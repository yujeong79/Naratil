"""
ë°ì´í„° ë¶„ë¥˜ ë° ID ë¶€ì—¬ ëª¨ë“ˆ
"""
import logging
from pyspark.sql import DataFrame, Window
from pyspark.sql.functions import col, count, avg, row_number

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

def split_by_industry_code(df_vector: DataFrame):
    """ì—…ì¢… ì½”ë“œë³„ í‰ê· ì„ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë¶„ë¦¬ ë° ì»¬ë ‰ì…˜ë³„ ID ë¶€ì—¬"""
    logger.info("ğŸ“Š ì—…ì¢… ì½”ë“œë³„ ë°ì´í„° ë¶„ë¦¬ ì¤‘...")

    # ê³µê³  ìˆ˜ ì§‘ê³„ ë° í‰ê·  ê³„ì‚°
    industry_count = df_vector.groupBy("industry_code").agg(count("bidNtceNo").alias("cnt"))
    avg_count = industry_count.agg(avg("cnt")).first()[0]
    logger.info(f"Industry í‰ê·  ê³µê³  ìˆ˜: {avg_count:.2f}")

    # ì¡°ê±´ í•„í„°ë§
    df_vector = df_vector.join(industry_count, on="industry_code", how="left")
    no_limit_df = df_vector.filter(col("industry_code").isNull())
    etc_df = df_vector.filter((col("cnt") < avg_count) & col("industry_code").isNotNull())
    greater_df = df_vector.filter(col("cnt") >= avg_count)

    # ì¹´í…Œê³ ë¦¬ë³„ ê°œìˆ˜ ì¶œë ¥
    no_limit_count = no_limit_df.count()
    etc_count = etc_df.count()
    greater_count = greater_df.count()

    logger.info("âœ… ë°ì´í„° ë¶„ë¦¬ ì™„ë£Œ:")
    logger.info(f"  - no_limit: {no_limit_count}ê±´")
    logger.info(f"  - industry_etc: {etc_count}ê±´")
    logger.info(f"  - industry_codeë³„ (í‰ê·  ì´ìƒ): {greater_count}ê±´")

    # no_limit ID ë¶€ì—¬
    if no_limit_count > 0:
        window_no_limit = Window.orderBy("bidNtceNo")
        no_limit_df = no_limit_df.withColumn("bidNtceId", row_number().over(window_no_limit) - 1)
        sample = no_limit_df.select("bidNtceId", "bidNtceNo").limit(3).collect()
        logger.info("no_limit bidNtceId ìƒ˜í”Œ:")
        for row in sample:
            logger.info(f"  bidNtceId: {row['bidNtceId']}, bidNtceNo: {row['bidNtceNo']}")

    # etc ID ë¶€ì—¬
    if etc_count > 0:
        window_etc = Window.orderBy("bidNtceNo")
        etc_df = etc_df.withColumn("bidNtceId", row_number().over(window_etc) - 1)
        sample = etc_df.select("bidNtceId", "bidNtceNo").limit(3).collect()
        logger.info("industry_etc bidNtceId ìƒ˜í”Œ:")
        for row in sample:
            logger.info(f"  bidNtceId: {row['bidNtceId']}, bidNtceNo: {row['bidNtceNo']}")

    return no_limit_df, etc_df, greater_df, industry_count

def add_sequential_id(df: DataFrame, window_spec: Window = None) -> DataFrame:
    """ë°ì´í„°í”„ë ˆì„ì— ì—°ì†ì ì¸ ID ì¶”ê°€ (0ë¶€í„° ì‹œì‘)"""
    if window_spec is None:
        window_spec = Window.orderBy("bidNtceNo")

    return df.withColumn("bidNtceId", row_number().over(window_spec) - 1)

def get_industry_dfs(greater_df: DataFrame, industry_count: DataFrame, avg_value: float):
    """ì—…ì¢… ì½”ë“œë³„ ë°ì´í„°í”„ë ˆì„ ìƒì„±"""
    result = []

    for row in industry_count.filter(col("cnt") >= avg_value).collect():
        code = row["industry_code"]
        count = row["cnt"]

        df_code = greater_df.filter(col("industry_code") == code)

        window_code = Window.orderBy("bidNtceNo")
        df_code = df_code.withColumn("bidNtceId", row_number().over(window_code) - 1)

        result.append((code, df_code, count))

    return result
