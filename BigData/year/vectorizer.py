"""
í…ìŠ¤íŠ¸ ë°ì´í„° ë²¡í„°í™” ì²˜ë¦¬ ëª¨ë“ˆ
"""
import logging
import pandas as pd
import re
from pyspark.sql.functions import col, when, pandas_udf
from pyspark.sql.types import ArrayType, FloatType
from sentence_transformers import SentenceTransformer

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ëª¨ë¸ ìºì‹± í•¨ìˆ˜
def get_model():
    """ëª¨ë¸ ë¡œë“œ (ìºì‹± ì ìš©)"""
    if not hasattr(get_model, "model"):
        logger.info("ğŸ¤– ëª¨ë¸ ë¡œë”© ì¤‘ (ìºì‹±ëœ ëª¨ë¸ ì‚¬ìš©)...")
        get_model.model = SentenceTransformer("jhgan/ko-sbert-sts")
        logger.info("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ìºì‹±ë¨)")
    return get_model.model

# í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜
def clean_and_filter(texts: pd.Series, stopwords: set) -> pd.Series:
    """í…ìŠ¤íŠ¸ ì •ì œ ë° ë¶ˆìš©ì–´ ì œê±°"""
    cleaned = texts.fillna("").apply(lambda x: re.sub(r"\[.*?\]|\(.*?\)|\{.*?\}|<.*?>", "", x))
    cleaned = cleaned.apply(lambda x: re.sub(r"[#@!*%^&]", "", x))
    cleaned = cleaned.apply(lambda x: re.sub(r"\s+", " ", x).strip())
    cleaned = cleaned.apply(
        lambda x: re.sub(
            r"\s+", " ",
            "".join([x.replace(word, "") for word in stopwords])
        ).strip()
    )
    return cleaned

def vectorize_data(spark, df, stopwords):
    """ë°ì´í„° ë²¡í„°í™”"""
    logger.info("âš™ï¸ ë°ì´í„° ë²¡í„°í™” ì‹œì‘...")

    @pandas_udf(ArrayType(FloatType()))
    def vectorize_udf(texts: pd.Series) -> pd.Series:
        cleaned = clean_and_filter(texts, stopwords)
        model = get_model()
        vectors = model.encode(cleaned.tolist(), convert_to_numpy=True)
        return pd.Series([vec.tolist() for vec in vectors])
    
    df_vector = df.withColumn("vectorNm", vectorize_udf(col("bidNtceNm")))

    columns_to_clean = [c for c in df_vector.columns if c != "vectorNm" and c != "bizs_parsed"]
    for col_name in columns_to_clean:
        df_vector = df_vector.withColumn(
            col_name,
            when((col(col_name) == "") | (col(col_name) == "NaN"), None).otherwise(col(col_name))
        )
    
    logger.info("âœ… ë²¡í„°í™” ë° null ì •ì œ ì™„ë£Œ")
    sample_vectors = df_vector.select("bidNtceNm", "vectorNm").limit(2)
    logger.info("ğŸ” ë²¡í„°í™” ê²°ê³¼ ìƒ˜í”Œ:")
    for row in sample_vectors.collect():
        logger.info(f"  ì›ë³¸ í…ìŠ¤íŠ¸: {row['bidNtceNm']}")
        logger.info(f"  ë²¡í„° ì°¨ì›: {len(row['vectorNm'])}")
        logger.info(f"  ë²¡í„° ì¼ë¶€: {row['vectorNm'][:5]}...")
        logger.info("---")
    
    return df_vector
