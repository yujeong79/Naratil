# ğŸ“Œ ë°°í¬ ê°€ì´ë“œ

### ëŒ€ìƒ í™˜ê²½

- EC2 ì„œë²„ 2ëŒ€ êµ¬ì„±
    - **EC2 (Frontend + API ì„œë²„ + Batch ì„œë²„ + DB)**
        - OS: Ubuntu 22.04
        - í¼ë¸”ë¦­ IP: 3.36.76.231
        - ì—­í• : Nginx, Vue frontend, Spring Boot API, Spring Batch, MySQL, MongoDB
    - **EC2 (Spark + HDFS)**
        - OS: Ubuntu 22.04
        - í¼ë¸”ë¦­ IP: 52.78.63.130
        - ì—­í• : Spark ì‘ì—…, Hadoop NameNode/DataNode

### í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### í”„ë¡œì íŠ¸ í´ë¡  ë° ì‹¤í–‰ ì¤€ë¹„

```bash
### ğŸ”¹ ì„œë²„ 1 (3.36.76.231)
git clone https://lab.ssafy.com/s12-bigdata-dist-sub1/S12P21A506
cd S12P21A506

### ğŸ”¹ ì„œë²„ 2 (52.78.63.130)
git clone https://lab.ssafy.com/s12-bigdata-dist-sub1/S12P21A506
cd S12P21A506/BigData
```

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì • - ì„œë²„ 1 (3.36.76.231)

- `Frontend/.env`
    
    ```bash
    VITE_APP_TITLE=ë‚˜ë¼ì¥í„° ì…ì°°ì •ë³´ ë¹…ë°ì´í„° í”Œë«í¼
    VITE_APP_PUBLIC_DATA_API_KEY=YOUR_PUBLIC_DATA_API_KEY
    VITE_APP_API_BASE_URL=https://j12a506.p.ssafy.io/api
    VITE_PUBLIC_DATA_SERVICE_KEY=FEmEpZ7W6QZ86IG2Ii9B3/aJXBuQL2upJWGmJoeEPJAEZykbjjAhiR08fbnbIvsRxRsxNauT9FFn+nQcE8XMqw==
    ```
    
- `batch/application.yml`
    
    ```bash
    spring:
  application:
    name: Naratil Batch

  batch:
    jdbc:
      initialize-schema: never  # ìŠ¤í”„ë§ ë°°ì¹˜ ì´ˆê¸°í™” ì •ì±…
    job:
      enabled: false             # ìë™ ë°°ì¹˜ ì‹¤í–‰ ë¹„í™œì„±í™”

  datasource:
    batch:
      jdbc-url: jdbc:mysql://3.36.76.231:3308/batchdb?useSSL=false&characterEncoding=UTF-8&allowPublicKeyRetrieval=true&serverTimezone=Asia/Seoul
      username: myuser
      password: mypassword
      driver-class-name: com.mysql.cj.jdbc.Driver

    business:
      jdbc-url: jdbc:mysql://3.36.76.231:3307/apidb?useSSL=false&characterEncoding=UTF-8&allowPublicKeyRetrieval=true&serverTimezone=Asia/Seoul
      username: myuser
      password: mypassword
      driver-class-name: com.mysql.cj.jdbc.Driver

    hikari:
      maximum-pool-size: 10
      minimum-idle: 5
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000

  data:
    mongodb:
      uri: mongodb://3.36.76.231:27017/naratil
      database: naratil

- `batch/application.properties`
    ```
    spring.application.name=naratil

    server.port=8080

    # MySQL
    spring.datasource.url=jdbc:mysql://j12a506.p.ssafy.io:3307/apidb?useSSL=false&serverTimezone=UTC
    spring.datasource.username=myuser
    spring.datasource.password=mypassword
    spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver

    # JPA
    spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL8Dialect

    spring.jpa.hibernate.ddl-auto=none
    spring.jpa.show-sql=true
    spring.jpa.properties.hibernate.format_sql=true

    # log level WARN > INFO
    logging.level.root: INFO

    # SQL


    # MongoDB
    spring.data.mongodb.uri=mongodb://j12a506.p.ssafy.io:27017
    spring.data.mongodb.database=naratil

    # Hibernate SQL
    spring.jpa.properties.hibernate.generate_statistics=false
    spring.jpa.properties.hibernate.use_sql_comments=true



    logging.level.org.hibernate.SQL=OFF
    logging.level.org.hibernate.type.descriptor.sql=OFF

    # JWT
    jwt.access-token-secret=your_very_long_access_token_secret_here_32_bytes_or_more

    jwt.refresh-token-secret=your_refresh_token_secret
    jwt.access-token-expiration=1800000
    jwt.refresh-token-expiration=604800000

  

    public-data-api:
    #  service-key: JVKsNwUuO8MwiXsdGgfzudKwGbMCxGQDlytz6wR5EyeMs/Ud4jddXTEWPOvmXfH0ZK23O59aB4oOO2GPfECrFA==
    service-key: Yc1sqYmFYTOaFpM5Z7/LBwgIyJnyLUXZY/Z2x6qrA+K00x5ohHijdSJsNNWfYrO44CL2xkkWMykdCYnJRbwLYg==
    springdoc:
    api-docs:
        path: /api-docs
    swagger-ui:
        path: /swagger-ui.html
        operations-sorter: method
        tags-sorter: alpha
        display-request-duration: true
    packages-to-scan: com.naratil.batch.controller


    # FAST API
    fastapi:
    base-url: http://localhost:8000/batch/fastapi
    api:
        industry-vector: /embedding/industry_vectors
        ntce-vector: /embedding/ntce_vectors
        ntce-similarity: /similarity/ntces
        ntce-recommend: /recommend/ntces


    logging:
    level:
        sun:
        rmi: warn
        javax:
        management: warn
        org.springframework.jdbc.core: ERROR
        org.springframework.jdbc.datasource: ERROR
        org.mongodb.drive.cluster: ERROR
        com.zaxxer.hikari.pool.HikariPool: ERROR
        o.s.d.mongodb.MongoTransactionManager: ERROR
        org.springframework.batch: INFO
        root: INFO
    #  file:
    #    name: logs/batch.log

    server:
    port: 8081
    tomcat:
        apr:
        enabled: false


    ```
    

    

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì • - ì„œë²„ 1 (52.78.63.130)

- `Bigdata/.env`
    
    ```bash
    HDFS_URL=
    HDFS_PATH=
    SERVICE_KEY=
    SPARK_MASTER_URL=
    SPARK_DRIVER_MEMORY=
    SPARK_EXECUTOR_MEMORY=
    SPARK_EXECUTOR_CORES=
    ```
    

### ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰

```bash
docker compose up --build -d

### ğŸ”¹ ì„œë²„ 1 (3.36.76.231)
# ì„œë¹„ìŠ¤ | ì´ë¦„ | ì„¤ëª… |	í¬íŠ¸
# nginx |	ì •ì  íŒŒì¼ ì„œë¹™ ë° ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ	| 80, 443
# api-server | Spring Boot ê¸°ë°˜ API ì„œë²„	| 8080
# batch-server	| Spring Boot ê¸°ë°˜ ë°°ì¹˜ ì²˜ë¦¬ ì„œë²„	| 8081
# fastapi	| Python FastAPI ê¸°ë°˜ AI ì¶”ì²œ ì„œë²„	| 8000
# mysql-api	| api-server ì „ìš© MySQL DB (apidb)	| 3307:3306
# mysql-batch	| batch-server ì „ìš© MySQL DB (batchdb)	| 3308:3306
# mongo	| ê³µí†µ MongoDB ì„œë²„	| 27017

### ğŸ”¹ ì„œë²„ 2 (52.78.63.130)
# ì„œë¹„ìŠ¤ | ì´ë¦„ | ì„¤ëª… |	í¬íŠ¸
# namenode |	HDFSì˜ NameNode ì—­í•  (íŒŒì¼ ë©”íƒ€ë°ì´í„° ê´€ë¦¬)	| 9870(HDFS UI), 8020(HDFS ì ‘ê·¼)
# datanode | HDFSì˜ DataNode ì—­í•  (ì‹¤ì œ ë°ì´í„° ì €ì¥)
# spark | PySpark ì‘ì—… ì‹¤í–‰ìš© Spark ì»¨í…Œì´ë„ˆ
```

```
docker-compose up -d --build
```

---


# ğŸ“Œ DB

ğŸ”‘ ì‚¬ìš©ì ë° ê¶Œí•œ ì„¤ì • (init-user.sql)

CREATE USER 'myuser'@'%' IDENTIFIED BY 'myuser';
GRANT ALL PRIVILEGES ON *.* TO 'myuser'@'%' WITH GRANT OPTION;
FLUSH PRIVILEGES;

ğŸ—ƒï¸ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ (schema.sql)
```
CREATE TABLE `corporation` (
  `corpid` bigint NOT NULL AUTO_INCREMENT,
  `bizno` varchar(10) NOT NULL,
  `corp_nm` varchar(100) NOT NULL,
  `ceo_nm` varchar(35) DEFAULT NULL,
  `emplye_num` varchar(10) DEFAULT NULL,
  `opbiz_dt` date DEFAULT NULL,
  `industry_id` bigint DEFAULT NULL,
  PRIMARY KEY (`corpid`),
  UNIQUE KEY `UKktf6f0nweev8yp7vyjxt22qgd` (`bizno`),
  KEY `FKqjmhfb8g5dyt1mh5chgrhxw8l` (`industry_id`),
  CONSTRAINT `FKqjmhfb8g5dyt1mh5chgrhxw8l` FOREIGN KEY (`industry_id`) REFERENCES `industry` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci

CREATE TABLE `industry` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `industry_code` bigint NOT NULL,
  `industry_name` varchar(200) NOT NULL,
  `category_code` bigint NOT NULL,
  `category_name` varchar(255) NOT NULL,
  `major_category_code` bigint NOT NULL,
  `major_category_name` varchar(255) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `industry_code_UNIQUE` (`industry_code`),
  KEY `idx_industry_category_code` (`category_code`),
  KEY `idx_industry_major_category_code` (`major_category_code`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci

CREATE TABLE `user` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `email` varchar(255) NOT NULL,
  `password` varchar(255) NOT NULL,
  `name` varchar(100) NOT NULL,
  `phone_number` varchar(11) DEFAULT NULL,
  `corpid` bigint DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `UKob8kqyqqgmefl0aco34akdtpe` (`email`),
  UNIQUE KEY `idx_user_email_password` (`email`,`password`),
  KEY `idx_user_corpid` (`corpid`),
  CONSTRAINT `FKcxh7u1bnv9w6dwduxsu4n42hu` FOREIGN KEY (`corpid`) REFERENCES `corporation` (`corpid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci

CREATE TABLE `recommend` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `corpid` bigint NOT NULL,
  `bid_ntce_id` bigint NOT NULL,
  `score` float NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_recommend_corpid_bid_ntce_id` (`corpid`,`bid_ntce_id`),
  CONSTRAINT `FKdp0ym32pbecr9weys1li60upb` FOREIGN KEY (`corpid`) REFERENCES `corporation` (`corpid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci

CREATE TABLE `favorite_bid` (
  `fav_id` bigint NOT NULL AUTO_INCREMENT,
  `user_id` bigint NOT NULL,
  `bid_ntce_id` bigint NOT NULL,
  PRIMARY KEY (`fav_id`),
  UNIQUE KEY `idx_favorite_bid_user_id_bid_ntce_id` (`user_id`,`bid_ntce_id`),
  CONSTRAINT `FK3ja3q5ydbmlvir2ky2ajxykoi` FOREIGN KEY (`user_id`) REFERENCES `user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci

```

# ğŸ“Œ ë²„ì „

## FE
```
í”„ë ˆì„ì›Œí¬ : Vue.js
ëŸ°íƒ€ì„ í™˜ê²½ : Node 20
ìƒíƒœ ê´€ë¦¬ : Pinia 
ë¹Œë“œ ë„êµ¬ : Vite 
íŒ¨í‚¤ì§€ ê´€ë¦¬ : npm 
CSS/ìŠ¤íƒ€ì¼ë§ : PrimeVue 4.2.5 , Tailwind CSS 3.4.17
ë°ì´í„° ì‹œê°í™” : Chart.js 
IDE : VS CODE ìµœì‹ 
```

## BE
```
ì–¸ì–´: Java 17 , Python 3.11 
í”„ë ˆì„ì›Œí¬: Spring Boot 3.4.3, FastAPI 0.45.0
ë°ì´í„°ë² ì´ìŠ¤: MySQL 8.0, MongoDB 8.0.5
ORM: JPA 
API: REST API (OpenAPI Documentation using Springdoc) 
ì»´íŒŒì¼ ë° ë¹Œë“œ: Gradle 8-jdk17 
ë°°í¬: Docker , AWS EC2 
```

## AI
```
Fast API : 0.115.12
Python 3.11.7
```

## DATA
```
hadoop 3.2.2
jdk-8
spark 3.4.2
pyspark 3.4.2
pymongo, numpy, pandas, sentence-transformer
```

# ì‹¤í–‰

## FE
1. ëª¨ë“ˆ ì„¤ì¹˜ ë° ì‹¤í–‰
```
npm install
npm run dev
```


## AI

1. ê°€ìƒí™˜ê²½ ìƒì„± ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜
```
python3 -m venv .venv
source .venv/bin/activate       # WindowsëŠ” .venv\Scripts\activate
pip install -r requirements.txt
```
2. FastAPI ì„œë²„ ì‹¤í–‰
```
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

## DATA
```

# 1. ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ì´ë™ (í™ˆ ë””ë ‰í† ë¦¬ ì‚¬ìš©)
cd ~

# 2. ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
df -h

# 3. ìŠ¤íŒŒí¬ 3.4.2 ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜ (/opt ë””ë ‰í† ë¦¬ì— ì„¤ì¹˜)
cd /opt
sudo wget https://archive.apache.org/dist/spark/spark-3.4.2/spark-3.4.2-bin-hadoop3.tgz
sudo tar -xvzf spark-3.4.2-bin-hadoop3.tgz
sudo mv spark-3.4.2-bin-hadoop3 spark
sudo rm spark-3.4.2-bin-hadoop3.tgz

# 4. ë””ìŠ¤í¬ ê³µê°„ì´ ì¶©ë¶„í•œ ìœ„ì¹˜ í™•ì¸ (ì—¬ìœ  ê³µê°„ì´ ë§ì€ ë””ë ‰í† ë¦¬ë¡œ ëŒ€ì²´ ê°€ëŠ¥)
# ì•„ë˜ ì˜ˆì‹œëŠ” í™ˆ ë””ë ‰í† ë¦¬ ì‚¬ìš© (í•„ìš”ì‹œ /mnt/data ë“±ìœ¼ë¡œ ë³€ê²½)
WORK_DIR=~/Project
mkdir -p $WORK_DIR
cd $WORK_DIR

# 5. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ìŠ¤íŒŒí¬ í™ˆ ë° ê²½ë¡œ ì„¤ì •)
echo 'export SPARK_HOME=/opt/spark' >> ~/.bashrc
echo 'export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin' >> ~/.bashrc
echo 'export PYSPARK_PYTHON=python3' >> ~/.bashrc

# 6. ì»¤ìŠ¤í…€ ìºì‹œ ìœ„ì¹˜ ì„¤ì • (ë””ìŠ¤í¬ ê³µê°„ ë¬¸ì œ ë°©ì§€)
echo 'export TRANSFORMERS_CACHE=~/Project/model_cache' >> ~/.bashrc
echo 'export HF_HOME=~/Project/model_cache' >> ~/.bashrc
echo 'export PIP_CACHE_DIR=~/Project/pip_cache' >> ~/.bashrc

# 7. í™˜ê²½ë³€ìˆ˜ ì ìš©
source ~/.bashrc

# 8. ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p ~/Project/model_cache
mkdir -p ~/Project/pip_cache

# 9. ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
mkdir -p ~/Project/venv
python3 -m venv ~/Project/venv
source ~/Project/venv/bin/activate

# 10. í•„ìš”í•œ Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ìºì‹œ ìµœì†Œí™”)
pip install --no-cache-dir --upgrade pip
pip install --no-cache-dir pyspark==3.4.2
pip install --no-cache-dir sentence-transformers // ì—¬ê¸°ì„œ no space ì—ëŸ¬ë‚¨, ë””ìŠ¤í¬ 16G ì´ë¯¸ full
pip install --no-cache-dir numpy pandas scikit-learn pyarrow sshtunnel pymongo
```