# 빅데이터 분산 사전 과제 정리

## 🎯 목표
- 병렬 분산 알고리즘 구현이 가능한 맵리듀스 프레임워크 이해
- 하둡 설치 및 맵리듀스 알고리즘 코드 실행



## 프로젝트 개요

### Scaling-out is superior to Scaling-up

**Scale-out** : 값싼 서버를 많이 이용

Scale-up : 값비싼 서버를 적게 이용

데이터 중심 (data-intensive) 어플리케이션 분야에서는 Scale-out을 선호

고가의 서버를 사용해도 성능이 선형으로 증가하지 않음 (일반적인 가격의 프로세스 두 개의 성능보다, 두 배 가격의 프로세서 한 개의 성능이 떨어짐)

**왜 맵리듀스를 사용할까?**

- 데이터 중심 프로세싱 (Data-intensive processing)
    
    수 천대의 컴퓨터를 묶어서 처리 ← 맵리듀스 프레임워크 역할
    
- 맵리듀스는 빅데이터를 이용한 효율적인 계산이 가능한 첫번째 프로그램 모델
    
    기존의 병렬 컴퓨팅 방법에서는 프로그래머가 낮은 레벨의 시스템 세부 내용까지 알고 시간을 쏟아야함 
    

## 맵리듀스 프레임워크

값싼 컴퓨터를 모아서 **클러스터**를 만들고, 여기에서 빅데이터를 처리하기 위한 **스케일러블**(scalable) 병렬 소프트웨어의 구현을 쉽게 할 수 있도록 도와주는 간단한 프로그래밍 모델

> **scalable**
사용자 수가 급증하거나 데이터가 급증해도 프로그램이 멈추거나 성능이 떨어질일이 없음
> 

구글의 맵리듀스(MapReduce) 또는 오픈소스 하둡(Hadoop) 등이 있음음

**드라이버**에 해당하는 메인 함수가 맵/리듀스 함수를 호출해서 처리 (맵리듀스 페이즈 수행)

### 맵리듀스 프로그래밍 모델

함수형 프로그래밍 (Functional programming) 언어의 형태

3가지 함수를 구현해서 제공해야 함 

- Main 함수
- Map 함수 (Key1, Val1) → [(key2, [Val2])]
- Reduce 함수 [(key2, [Val2])] → [(key3, Val3)]

각각의 레코드(record) 또는 튜플(tuple)은 키-밸류 (Key, Value) 쌍으로 표현됨

메인 함수를 한 개의 **마스터 머신(master machine)**에서 수행하는데, 이 머신은 맵 함수를 수행하기 전 **전처리**를 하거나 리듀스 함수의 결과를 **후처리**하는데 사용됨

컴퓨팅은 맵과 리듀스 함수 한 쌍으로 이루어진 **맵리듀스 페이즈**를 한 번 이상 반복 수행할 수 있음

맵리듀스 페이즈는 **맵 함수 > (컴바인 함수) > 리듀스 함수**를 호출

### 맵리듀스 페이즈

1. 맵 페이즈
    
    여러 파티션(partition)에 병렬 분산으로 호출되어 수행됨
    
    각 머신마다 수행된 Mapper는 입력 데이터의 한 줄마다 맵 함수를 호출
    
    맵 함수는 (Key, Value) 쌍 형태로 결과를 출력, 여러 머신에 나누어 보내 같은 KEY를 가진 쌍은 같은 머신으로 보내짐
    
2. 셔플링 페이즈
    
    맵 페이즈에서 보내진 쌍을 KEY를 이용해서 정렬한 후에 각각의 KEY마다 같은 KEY를 가진 쌍을 모아서 Value-List를 만들어 (Key, Value-List) 형태로 KEY에 따라 여러 머신에 분산하여 보냄
    
3. 리듀스 페이즈
    
    셔플링 페이즈에서 보내진 (Key, Value-List) 쌍 마다 리듀스 함수를 호출
    
    출력이 있으면 (Key, Value)쌍 형태로 출력
    

## Hadoop

Apache 프로젝트의 맵리듀스 프레임워크의 오픈 소스

빅데이터를 수천 대의 값싼 컴퓨터에서 병렬 처리하기 위해 분산함

**하둡 분산 파일 시스템 (Hadoop Distributed File System - HDFS)**

빅데이터 파일을 여러 대의 컴푸터에 나누어서 저장

각 파일은 여러 개의 순차적인 블록으로 저장

하나의 파일의 각각의 블록은 폴트 톨러런스(fault tolerance)를 위해 여러 개로 복사되어 여러 머신에 저장

> **폴트 톨러런스(fault tolerance)**
시스템을 구성하는 부품의 일부에서 결함(fault) 또는 고장(failure)이 발생하여도 정상적 혹은 부분적으로 기능을 수행할 수 있는 것
> 

**구성요소**

MapReduce : 소프트웨어의 수행을 분산

HDFS : 데이터를 분산

한 개의 네임노드(master)와 여러 개의 데이터노드(slaves)

- Namenode : 파일 시스템을 관리하고 클라이언트가 파일에 접근할 수 있게 함

- Datanode : 컴퓨터에 들어있는 데이터를 접근할 수 있게 함

자바 프로그래밍 언어로 맵리듀스 알고리즘을 구현

### 맵리듀스의 함수

1. 맵 함수
    
    `org.apache.hadoop.mapreduce` 패키지의 Mapper 클래스 상속 받아 map 메소드 수정
    
    입력 텍스트 파일에서 라인 단위로 호출됨. 
    
    KEY : 입력 텍스트 파일의 첫 문자에서 해당 라인 첫 문자까지의 오프셋. 
    VALUE : 해당 라인 전체 
    
2. 리듀스 함수
    
    `org.apache.hadoop.mapreduce` 패키지의 Reducer 클래스 상속 받아 reduce 메소드 수정
    
    셔플링 페이즈를 거친 (KEY, VALUE_LIST) 형태로 입력 데이터를 받음
    
    ※ KEY, VALUE_LIST : 같은 KEY를 갖는 KEY, VALUE의 쌍
    
3. 컴파인 함수
    
    각각의 머신에서 리듀스 함수를 이용하는 것과 유사
    
    각 머신에서 맵 함수의 출력 크기를 줄여서 셔플링 페이즈 비용을 줄임
    

## Overview of MapReduce

**Mapper와 Reducer**

각 머신에서 독립적으로 수행되고, 각각 Map함수와 Reduce 함수를 수행

필요하면 setup()과 cleanup() 수행

setup() : 첫 Map 함수나 Reduce 함수가 호출되기 전에 맨 먼저 수행
모든 Map함수들에게 Braodcast해서 전달해야 할 파라미터들 정보를 Main 함수에서 받아오는데 사용
모든 Map 함수들이 공유하는 자료구조를 초기화 하는데 사용

cleanup() : 마지막 Map 함수나 Reduce 함수가 끝나고 나면 수행
모든 Map 함수들이 공유하는 자료구조의 결과를 출력하는데 사용 

Combine functions : Map함수의 결과에 대해 Reduce 함수가 하는 일을 부분적으로 수행하여 셔플링 비용과 네트워크 트래픽을 감소 시킴

한 개의 MapReduce JOB을 수행할 때 Map 페이즈만 수행하고 중단할 수 있음.

## Hadoop 설치하고 MapReduce 알고리즘을 수행시키기

1. 개발 환경 구성 (window 기준)

- ~~VMware~~ → VirtualBox : https://www.virtualbox.org/wiki/Downloads
- Ubuntu : https://ubuntu.com/download/desktop
- hadoop : https://hadoop.apache.org/releases.html

**가상 머신 만들기**

이름 : ubuntu

ISO 이미지 : ubuntu 파일 위치

**무인 게스트**

사용자 이름 :hadoop

**하드웨어**

메모리, 프로세서 늘리면 조금 빨라짐


2. console 실행

```bash
$ wget http://kdd.snu.ac.kr/~kddlab/Project.tar.gz // 인터넷에서 파일 다운로드

$ tar zxf Project.tar.gz // 파일 압축 해제
$ sudo chown -R hadoop:hadoop Project // 파일 소유권 변경
$ cd Project
$ sudo mv hadoop-3.2.2 /usr/local/hadoop // Hadoop 설치 디렉터리 이동
$ sudo apt update // 패키지 목록 업데이트
$ sudo apt install ssh openjdk-8-jdk ant -y // 필요한 패키지 설치
$ ./set_hadoop_env.sh // Hadoop 환경 설정 스크립트 실행
$ source ~/.bashrc // 환경변수 용
```

3. Hadoop 실행 준비

```bash
// hadoop@ubuntu:~$ 인지 확인!! 아니라면 Ctrl+d
// 루트 디렉토리 (HOME)에서 입력
$ ssh-keygen -t rsa -P ""
// Enter file in which to save the key (/home/hadoop/.ssh/id_rsa):
Enter

$ cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
$ ssh localhost
// Are you sure you want to continue connecting (yes/no/[fingerprint])?
yes
// 비밀번호 물어보지 않고 prompt가 뜨면 성공

$ source .bashrc
$ hdfs namenode -format
$ start-dfs.sh
$ start-yarn.sh
$ jps
// **NameNode**
// **SecondaryNameNode**
// **DataNode**
// TaskTracker (stanalone에서 불필요)
// JobTracker (stanalone에서 불필요)
// **NameNode, SecondaryNameNode, DataNode** 3개 떠있으면 성공
```
   
4. Hadoop에서 맵리듀스 코드 실행

데이터 생성은 Linux, MapReduce 코드와 입력 데이터는 HDFS에 옮겨서 MapReduce 알고리즘을 수행함

**Linux 디렉토리**

`src/` (맵리듀스 코드)

⌞ `Driver.java` (맵리듀스 코드 컴파일을 위한 파일)

⌞ `Wordcount.java`

`template/` (과제를 위한 template)

`datagen/` (과제 데이터를 생성하기 위한 코드)

`data/` (과제를 위한 데이터)

`build.html`  (맵리듀스 코드 컴파일을 위한 파일)


**Hadoop 디렉토리**

`wordcount_test/`  (맵리듀스 코드 실행을 위한 데이터 디렉토리)

`wordcount_test_out/`  (맵리듀스 코드 실행 결과를 저장하는 디렉토리)

---

```bash
$ cd ./Project/src
$ ls
// Driver.java, Wordcount.java 확인
$ vi Driver.java
// pgd.addClass("wordcount", Wordcount.class, "A map/reduce program that perform word counting.");
// 위 코드가 있는지 확인
```


📌 `pgd.addClass("wordcount", Wordcount.class, "A map/reduce program that perform word counting.");`

새로운 맵리듀스 코드를 만들 때마다 Driver.java 파일에 pgd.addClass로 만들어서 append 해야 함

Driver.java 파일이 바뀌면 Project 디렉토리에서 ant를 다시 수행해야 함

---

📌 **Linux에서 유닉스 몇가지 명령어들**

cd, ls, cat (파일 내용 출력), cp (파일 복사), mkdir (새로운 디렉토리 생성), vi (읽기, 수정)

**HDFS에서 유닉스 명령어를 대부분 그대로 사용**

`hdfs dfs -유닉스 명령어` 로 사용

---

5. 맵리듀스 코드 컴파일하기

```bash
$ cd ./hadoop/Project/
$ ant
// Unix의 make
// ssafy.jar를 생성
// Project/build.xml 에 정의한 대로 수행
```

📌 **Hadoop에서 맵리듀스 자바 코드 실행 방법**

```bash
$ hadoop jar [jar file] [program name] <input arguments ...>
// ex) hadoop jar ssafy.jar wordcount wordcount_test wardcount_test_out
```

`pgd.addClass("wordcount", Wordcount.class, "A map/reduce program that perform word counting.");` 에서 첫번째 인자를 `[program name]`에 넣기

---

**Wordcount MapReduce 알고리즘 코드 실행**

```bash
// home/hadoop 에서
$ cd Project/data
~/Project/data$ hdfs dfs -mkdir wordcount_test // wordcount_test 디렉토리 생성
~/Project/data$ hdfs dfs -put wordcount-data.txt wordcount_test // 테스트 데이터를 hdfs에 복사

// 반드시 wordcount_test_out 디렉토리를 삭제한 후 실행 해야함
????$ hdfs dfs -rm -r wordcount_test_out

// Hadoop 실행 (안되면 컴파일 다시)
~/Project$ hadoop jar ssafy.jar wordcount wordcount_test wordcount_test_out

// 결과 확인
// reduce 함수를 2개 사용하면 아래와 같이 출력 파일이 2개 생성됨
~/Project$ hdfs dfs -cat wordcount_test_out/part-r-00000 | more
~/Project$ hdfs dfs -cat wordcount_test_out/part-r-00001 | more
```

📌 **새로운 맵리듀스 알고리즘 코드를 만든 다음에 컴파일을 하는 방법**

- 소스 코드 파일을 Project/src/ 디렉토리에 넣는다.
- Project/src 디렉토리에 있는 Driver.java 파일에 append
- Project 디렉토리에서 `ant` 수행

---

### 맵리듀스 입출력에서 사용 가능한 디폴트 클래스

맵리듀스 입출력에 사용되는 타입은 이미 정의되어 있음

**입출력에 사용할 수 있는 클래스와 해당 자바 타입**

- Text: string
- IntWritable: int
- LongWritable: long
- FloatWritable: float
- DoubleWritable: double

만약 새로운 클래스를 정의해서 입출력에 사용하고 싶으면 필요한 여러 함수도 같이 정의해줘야 함