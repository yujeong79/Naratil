# ë¹…ë°ì´í„° ë¶„ì‚° ì‚¬ì „ ê³¼ì œ ì •ë¦¬

## ğŸ¯ ëª©í‘œ
- ë³‘ë ¬ ë¶„ì‚° ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ì´ ê°€ëŠ¥í•œ ë§µë¦¬ë“€ìŠ¤ í”„ë ˆì„ì›Œí¬ ì´í•´
- í•˜ë‘¡ ì„¤ì¹˜ ë° ë§µë¦¬ë“€ìŠ¤ ì•Œê³ ë¦¬ì¦˜ ì½”ë“œ ì‹¤í–‰



## í”„ë¡œì íŠ¸ ê°œìš”

### Scaling-out is superior to Scaling-up

**Scale-out** : ê°’ì‹¼ ì„œë²„ë¥¼ ë§ì´ ì´ìš©

Scale-up : ê°’ë¹„ì‹¼ ì„œë²„ë¥¼ ì ê²Œ ì´ìš©

ë°ì´í„° ì¤‘ì‹¬ (data-intensive) ì–´í”Œë¦¬ì¼€ì´ì…˜ ë¶„ì•¼ì—ì„œëŠ” Scale-outì„ ì„ í˜¸

ê³ ê°€ì˜ ì„œë²„ë¥¼ ì‚¬ìš©í•´ë„ ì„±ëŠ¥ì´ ì„ í˜•ìœ¼ë¡œ ì¦ê°€í•˜ì§€ ì•ŠìŒ (ì¼ë°˜ì ì¸ ê°€ê²©ì˜ í”„ë¡œì„¸ìŠ¤ ë‘ ê°œì˜ ì„±ëŠ¥ë³´ë‹¤, ë‘ ë°° ê°€ê²©ì˜ í”„ë¡œì„¸ì„œ í•œ ê°œì˜ ì„±ëŠ¥ì´ ë–¨ì–´ì§)

**ì™œ ë§µë¦¬ë“€ìŠ¤ë¥¼ ì‚¬ìš©í• ê¹Œ?**

- ë°ì´í„° ì¤‘ì‹¬ í”„ë¡œì„¸ì‹± (Data-intensive processing)
    
    ìˆ˜ ì²œëŒ€ì˜ ì»´í“¨í„°ë¥¼ ë¬¶ì–´ì„œ ì²˜ë¦¬ â† ë§µë¦¬ë“€ìŠ¤ í”„ë ˆì„ì›Œí¬ ì—­í• 
    
- ë§µë¦¬ë“€ìŠ¤ëŠ” ë¹…ë°ì´í„°ë¥¼ ì´ìš©í•œ íš¨ìœ¨ì ì¸ ê³„ì‚°ì´ ê°€ëŠ¥í•œ ì²«ë²ˆì§¸ í”„ë¡œê·¸ë¨ ëª¨ë¸
    
    ê¸°ì¡´ì˜ ë³‘ë ¬ ì»´í“¨íŒ… ë°©ë²•ì—ì„œëŠ” í”„ë¡œê·¸ë˜ë¨¸ê°€ ë‚®ì€ ë ˆë²¨ì˜ ì‹œìŠ¤í…œ ì„¸ë¶€ ë‚´ìš©ê¹Œì§€ ì•Œê³  ì‹œê°„ì„ ìŸì•„ì•¼í•¨ 
    

## ë§µë¦¬ë“€ìŠ¤ í”„ë ˆì„ì›Œí¬

ê°’ì‹¼ ì»´í“¨í„°ë¥¼ ëª¨ì•„ì„œ **í´ëŸ¬ìŠ¤í„°**ë¥¼ ë§Œë“¤ê³ , ì—¬ê¸°ì—ì„œ ë¹…ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ **ìŠ¤ì¼€ì¼ëŸ¬ë¸”**(scalable) ë³‘ë ¬ ì†Œí”„íŠ¸ì›¨ì–´ì˜ êµ¬í˜„ì„ ì‰½ê²Œ í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ê°„ë‹¨í•œ í”„ë¡œê·¸ë˜ë° ëª¨ë¸

> **scalable**
ì‚¬ìš©ì ìˆ˜ê°€ ê¸‰ì¦í•˜ê±°ë‚˜ ë°ì´í„°ê°€ ê¸‰ì¦í•´ë„ í”„ë¡œê·¸ë¨ì´ ë©ˆì¶”ê±°ë‚˜ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆì¼ì´ ì—†ìŒ
> 

êµ¬ê¸€ì˜ ë§µë¦¬ë“€ìŠ¤(MapReduce) ë˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ í•˜ë‘¡(Hadoop) ë“±ì´ ìˆìŒìŒ

**ë“œë¼ì´ë²„**ì— í•´ë‹¹í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜ê°€ ë§µ/ë¦¬ë“€ìŠ¤ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ì„œ ì²˜ë¦¬ (ë§µë¦¬ë“€ìŠ¤ í˜ì´ì¦ˆ ìˆ˜í–‰)

### ë§µë¦¬ë“€ìŠ¤ í”„ë¡œê·¸ë˜ë° ëª¨ë¸

í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë° (Functional programming) ì–¸ì–´ì˜ í˜•íƒœ

3ê°€ì§€ í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ì„œ ì œê³µí•´ì•¼ í•¨ 

- Main í•¨ìˆ˜
- Map í•¨ìˆ˜ (Key1, Val1) â†’ [(key2, [Val2])]
- Reduce í•¨ìˆ˜ [(key2, [Val2])] â†’ [(key3, Val3)]

ê°ê°ì˜ ë ˆì½”ë“œ(record) ë˜ëŠ” íŠœí”Œ(tuple)ì€ í‚¤-ë°¸ë¥˜ (Key, Value) ìŒìœ¼ë¡œ í‘œí˜„ë¨

ë©”ì¸ í•¨ìˆ˜ë¥¼ í•œ ê°œì˜ **ë§ˆìŠ¤í„° ë¨¸ì‹ (master machine)**ì—ì„œ ìˆ˜í–‰í•˜ëŠ”ë°, ì´ ë¨¸ì‹ ì€ ë§µ í•¨ìˆ˜ë¥¼ ìˆ˜í–‰í•˜ê¸° ì „ **ì „ì²˜ë¦¬**ë¥¼ í•˜ê±°ë‚˜ ë¦¬ë“€ìŠ¤ í•¨ìˆ˜ì˜ ê²°ê³¼ë¥¼ **í›„ì²˜ë¦¬**í•˜ëŠ”ë° ì‚¬ìš©ë¨

ì»´í“¨íŒ…ì€ ë§µê³¼ ë¦¬ë“€ìŠ¤ í•¨ìˆ˜ í•œ ìŒìœ¼ë¡œ ì´ë£¨ì–´ì§„ **ë§µë¦¬ë“€ìŠ¤ í˜ì´ì¦ˆ**ë¥¼ í•œ ë²ˆ ì´ìƒ ë°˜ë³µ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ

ë§µë¦¬ë“€ìŠ¤ í˜ì´ì¦ˆëŠ” **ë§µ í•¨ìˆ˜ > (ì»´ë°”ì¸ í•¨ìˆ˜) > ë¦¬ë“€ìŠ¤ í•¨ìˆ˜**ë¥¼ í˜¸ì¶œ

### ë§µë¦¬ë“€ìŠ¤ í˜ì´ì¦ˆ

1. ë§µ í˜ì´ì¦ˆ
    
    ì—¬ëŸ¬ íŒŒí‹°ì…˜(partition)ì— ë³‘ë ¬ ë¶„ì‚°ìœ¼ë¡œ í˜¸ì¶œë˜ì–´ ìˆ˜í–‰ë¨
    
    ê° ë¨¸ì‹ ë§ˆë‹¤ ìˆ˜í–‰ëœ MapperëŠ” ì…ë ¥ ë°ì´í„°ì˜ í•œ ì¤„ë§ˆë‹¤ ë§µ í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
    
    ë§µ í•¨ìˆ˜ëŠ” (Key, Value) ìŒ í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ì¶œë ¥, ì—¬ëŸ¬ ë¨¸ì‹ ì— ë‚˜ëˆ„ì–´ ë³´ë‚´ ê°™ì€ KEYë¥¼ ê°€ì§„ ìŒì€ ê°™ì€ ë¨¸ì‹ ìœ¼ë¡œ ë³´ë‚´ì§
    
2. ì…”í”Œë§ í˜ì´ì¦ˆ
    
    ë§µ í˜ì´ì¦ˆì—ì„œ ë³´ë‚´ì§„ ìŒì„ KEYë¥¼ ì´ìš©í•´ì„œ ì •ë ¬í•œ í›„ì— ê°ê°ì˜ KEYë§ˆë‹¤ ê°™ì€ KEYë¥¼ ê°€ì§„ ìŒì„ ëª¨ì•„ì„œ Value-Listë¥¼ ë§Œë“¤ì–´ (Key, Value-List) í˜•íƒœë¡œ KEYì— ë”°ë¼ ì—¬ëŸ¬ ë¨¸ì‹ ì— ë¶„ì‚°í•˜ì—¬ ë³´ëƒ„
    
3. ë¦¬ë“€ìŠ¤ í˜ì´ì¦ˆ
    
    ì…”í”Œë§ í˜ì´ì¦ˆì—ì„œ ë³´ë‚´ì§„ (Key, Value-List) ìŒ ë§ˆë‹¤ ë¦¬ë“€ìŠ¤ í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
    
    ì¶œë ¥ì´ ìˆìœ¼ë©´ (Key, Value)ìŒ í˜•íƒœë¡œ ì¶œë ¥
    

## Hadoop

Apache í”„ë¡œì íŠ¸ì˜ ë§µë¦¬ë“€ìŠ¤ í”„ë ˆì„ì›Œí¬ì˜ ì˜¤í”ˆ ì†ŒìŠ¤

ë¹…ë°ì´í„°ë¥¼ ìˆ˜ì²œ ëŒ€ì˜ ê°’ì‹¼ ì»´í“¨í„°ì—ì„œ ë³‘ë ¬ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ë¶„ì‚°í•¨

**í•˜ë‘¡ ë¶„ì‚° íŒŒì¼ ì‹œìŠ¤í…œ (Hadoop Distributed File System - HDFS)**

ë¹…ë°ì´í„° íŒŒì¼ì„ ì—¬ëŸ¬ ëŒ€ì˜ ì»´í‘¸í„°ì— ë‚˜ëˆ„ì–´ì„œ ì €ì¥

ê° íŒŒì¼ì€ ì—¬ëŸ¬ ê°œì˜ ìˆœì°¨ì ì¸ ë¸”ë¡ìœ¼ë¡œ ì €ì¥

í•˜ë‚˜ì˜ íŒŒì¼ì˜ ê°ê°ì˜ ë¸”ë¡ì€ í´íŠ¸ í†¨ëŸ¬ëŸ°ìŠ¤(fault tolerance)ë¥¼ ìœ„í•´ ì—¬ëŸ¬ ê°œë¡œ ë³µì‚¬ë˜ì–´ ì—¬ëŸ¬ ë¨¸ì‹ ì— ì €ì¥

> **í´íŠ¸ í†¨ëŸ¬ëŸ°ìŠ¤(fault tolerance)**
ì‹œìŠ¤í…œì„ êµ¬ì„±í•˜ëŠ” ë¶€í’ˆì˜ ì¼ë¶€ì—ì„œ ê²°í•¨(fault) ë˜ëŠ” ê³ ì¥(failure)ì´ ë°œìƒí•˜ì—¬ë„ ì •ìƒì  í˜¹ì€ ë¶€ë¶„ì ìœ¼ë¡œ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ê²ƒ
> 

**êµ¬ì„±ìš”ì†Œ**

MapReduce : ì†Œí”„íŠ¸ì›¨ì–´ì˜ ìˆ˜í–‰ì„ ë¶„ì‚°

HDFS : ë°ì´í„°ë¥¼ ë¶„ì‚°

í•œ ê°œì˜ ë„¤ì„ë…¸ë“œ(master)ì™€ ì—¬ëŸ¬ ê°œì˜ ë°ì´í„°ë…¸ë“œ(slaves)

- Namenode : íŒŒì¼ ì‹œìŠ¤í…œì„ ê´€ë¦¬í•˜ê³  í´ë¼ì´ì–¸íŠ¸ê°€ íŒŒì¼ì— ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ í•¨

- Datanode : ì»´í“¨í„°ì— ë“¤ì–´ìˆëŠ” ë°ì´í„°ë¥¼ ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ í•¨

ìë°” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ ë§µë¦¬ë“€ìŠ¤ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„

### ë§µë¦¬ë“€ìŠ¤ì˜ í•¨ìˆ˜

1. ë§µ í•¨ìˆ˜
    
    `org.apache.hadoop.mapreduce` íŒ¨í‚¤ì§€ì˜ Mapper í´ë˜ìŠ¤ ìƒì† ë°›ì•„ map ë©”ì†Œë“œ ìˆ˜ì •
    
    ì…ë ¥ í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ë¼ì¸ ë‹¨ìœ„ë¡œ í˜¸ì¶œë¨. 
    
    KEY : ì…ë ¥ í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ì²« ë¬¸ìì—ì„œ í•´ë‹¹ ë¼ì¸ ì²« ë¬¸ìê¹Œì§€ì˜ ì˜¤í”„ì…‹. 
    VALUE : í•´ë‹¹ ë¼ì¸ ì „ì²´ 
    
2. ë¦¬ë“€ìŠ¤ í•¨ìˆ˜
    
    `org.apache.hadoop.mapreduce` íŒ¨í‚¤ì§€ì˜ Reducer í´ë˜ìŠ¤ ìƒì† ë°›ì•„ reduce ë©”ì†Œë“œ ìˆ˜ì •
    
    ì…”í”Œë§ í˜ì´ì¦ˆë¥¼ ê±°ì¹œ (KEY, VALUE_LIST) í˜•íƒœë¡œ ì…ë ¥ ë°ì´í„°ë¥¼ ë°›ìŒ
    
    â€» KEY, VALUE_LIST : ê°™ì€ KEYë¥¼ ê°–ëŠ” KEY, VALUEì˜ ìŒ
    
3. ì»´íŒŒì¸ í•¨ìˆ˜
    
    ê°ê°ì˜ ë¨¸ì‹ ì—ì„œ ë¦¬ë“€ìŠ¤ í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ëŠ” ê²ƒê³¼ ìœ ì‚¬
    
    ê° ë¨¸ì‹ ì—ì„œ ë§µ í•¨ìˆ˜ì˜ ì¶œë ¥ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ ì…”í”Œë§ í˜ì´ì¦ˆ ë¹„ìš©ì„ ì¤„ì„
    

## Overview of MapReduce

**Mapperì™€ Reducer**

ê° ë¨¸ì‹ ì—ì„œ ë…ë¦½ì ìœ¼ë¡œ ìˆ˜í–‰ë˜ê³ , ê°ê° Mapí•¨ìˆ˜ì™€ Reduce í•¨ìˆ˜ë¥¼ ìˆ˜í–‰

í•„ìš”í•˜ë©´ setup()ê³¼ cleanup() ìˆ˜í–‰

setup() : ì²« Map í•¨ìˆ˜ë‚˜ Reduce í•¨ìˆ˜ê°€ í˜¸ì¶œë˜ê¸° ì „ì— ë§¨ ë¨¼ì € ìˆ˜í–‰
ëª¨ë“  Mapí•¨ìˆ˜ë“¤ì—ê²Œ Braodcastí•´ì„œ ì „ë‹¬í•´ì•¼ í•  íŒŒë¼ë¯¸í„°ë“¤ ì •ë³´ë¥¼ Main í•¨ìˆ˜ì—ì„œ ë°›ì•„ì˜¤ëŠ”ë° ì‚¬ìš©
ëª¨ë“  Map í•¨ìˆ˜ë“¤ì´ ê³µìœ í•˜ëŠ” ìë£Œêµ¬ì¡°ë¥¼ ì´ˆê¸°í™” í•˜ëŠ”ë° ì‚¬ìš©

cleanup() : ë§ˆì§€ë§‰ Map í•¨ìˆ˜ë‚˜ Reduce í•¨ìˆ˜ê°€ ëë‚˜ê³  ë‚˜ë©´ ìˆ˜í–‰
ëª¨ë“  Map í•¨ìˆ˜ë“¤ì´ ê³µìœ í•˜ëŠ” ìë£Œêµ¬ì¡°ì˜ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ”ë° ì‚¬ìš© 

Combine functions : Mapí•¨ìˆ˜ì˜ ê²°ê³¼ì— ëŒ€í•´ Reduce í•¨ìˆ˜ê°€ í•˜ëŠ” ì¼ì„ ë¶€ë¶„ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ì—¬ ì…”í”Œë§ ë¹„ìš©ê³¼ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ì„ ê°ì†Œ ì‹œí‚´

í•œ ê°œì˜ MapReduce JOBì„ ìˆ˜í–‰í•  ë•Œ Map í˜ì´ì¦ˆë§Œ ìˆ˜í–‰í•˜ê³  ì¤‘ë‹¨í•  ìˆ˜ ìˆìŒ.

## Hadoop ì„¤ì¹˜í•˜ê³  MapReduce ì•Œê³ ë¦¬ì¦˜ì„ ìˆ˜í–‰ì‹œí‚¤ê¸°

1. ê°œë°œ í™˜ê²½ êµ¬ì„± (window ê¸°ì¤€)

- ~~VMware~~ â†’ VirtualBox : https://www.virtualbox.org/wiki/Downloads
- Ubuntu : https://ubuntu.com/download/desktop
- hadoop : https://hadoop.apache.org/releases.html

**ê°€ìƒ ë¨¸ì‹  ë§Œë“¤ê¸°**

ì´ë¦„ : ubuntu

ISO ì´ë¯¸ì§€ : ubuntu íŒŒì¼ ìœ„ì¹˜

**ë¬´ì¸ ê²ŒìŠ¤íŠ¸**

ì‚¬ìš©ì ì´ë¦„ :hadoop

**í•˜ë“œì›¨ì–´**

ë©”ëª¨ë¦¬, í”„ë¡œì„¸ì„œ ëŠ˜ë¦¬ë©´ ì¡°ê¸ˆ ë¹¨ë¼ì§


2. console ì‹¤í–‰

```bash
$ wget http://kdd.snu.ac.kr/~kddlab/Project.tar.gz // ì¸í„°ë„·ì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ

$ tar zxf Project.tar.gz // íŒŒì¼ ì••ì¶• í•´ì œ
$ sudo chown -R hadoop:hadoop Project // íŒŒì¼ ì†Œìœ ê¶Œ ë³€ê²½
$ cd Project
$ sudo mv hadoop-3.2.2 /usr/local/hadoop // Hadoop ì„¤ì¹˜ ë””ë ‰í„°ë¦¬ ì´ë™
$ sudo apt update // íŒ¨í‚¤ì§€ ëª©ë¡ ì—…ë°ì´íŠ¸
$ sudo apt install ssh openjdk-8-jdk ant -y // í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
$ ./set_hadoop_env.sh // Hadoop í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
$ source ~/.bashrc // í™˜ê²½ë³€ìˆ˜ ìš©
```

3. Hadoop ì‹¤í–‰ ì¤€ë¹„

```bash
// hadoop@ubuntu:~$ ì¸ì§€ í™•ì¸!! ì•„ë‹ˆë¼ë©´ Ctrl+d
// ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (HOME)ì—ì„œ ì…ë ¥
$ ssh-keygen -t rsa -P ""
// Enter file in which to save the key (/home/hadoop/.ssh/id_rsa):
Enter

$ cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
$ ssh localhost
// Are you sure you want to continue connecting (yes/no/[fingerprint])?
yes
// ë¹„ë°€ë²ˆí˜¸ ë¬¼ì–´ë³´ì§€ ì•Šê³  promptê°€ ëœ¨ë©´ ì„±ê³µ

$ source .bashrc
$ hdfs namenode -format
$ start-dfs.sh
$ start-yarn.sh
$ jps
// **NameNode**
// **SecondaryNameNode**
// **DataNode**
// TaskTracker (stanaloneì—ì„œ ë¶ˆí•„ìš”)
// JobTracker (stanaloneì—ì„œ ë¶ˆí•„ìš”)
// **NameNode, SecondaryNameNode, DataNode** 3ê°œ ë– ìˆìœ¼ë©´ ì„±ê³µ
```
   
4. Hadoopì—ì„œ ë§µë¦¬ë“€ìŠ¤ ì½”ë“œ ì‹¤í–‰

ë°ì´í„° ìƒì„±ì€ Linux, MapReduce ì½”ë“œì™€ ì…ë ¥ ë°ì´í„°ëŠ” HDFSì— ì˜®ê²¨ì„œ MapReduce ì•Œê³ ë¦¬ì¦˜ì„ ìˆ˜í–‰í•¨

**Linux ë””ë ‰í† ë¦¬**

`src/` (ë§µë¦¬ë“€ìŠ¤ ì½”ë“œ)

âŒ `Driver.java` (ë§µë¦¬ë“€ìŠ¤ ì½”ë“œ ì»´íŒŒì¼ì„ ìœ„í•œ íŒŒì¼)

âŒ `Wordcount.java`

`template/` (ê³¼ì œë¥¼ ìœ„í•œ template)

`datagen/` (ê³¼ì œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ ì½”ë“œ)

`data/` (ê³¼ì œë¥¼ ìœ„í•œ ë°ì´í„°)

`build.html`  (ë§µë¦¬ë“€ìŠ¤ ì½”ë“œ ì»´íŒŒì¼ì„ ìœ„í•œ íŒŒì¼)


**Hadoop ë””ë ‰í† ë¦¬**

`wordcount_test/`  (ë§µë¦¬ë“€ìŠ¤ ì½”ë“œ ì‹¤í–‰ì„ ìœ„í•œ ë°ì´í„° ë””ë ‰í† ë¦¬)

`wordcount_test_out/`  (ë§µë¦¬ë“€ìŠ¤ ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ë””ë ‰í† ë¦¬)

---

```bash
$ cd ./Project/src
$ ls
// Driver.java, Wordcount.java í™•ì¸
$ vi Driver.java
// pgd.addClass("wordcount", Wordcount.class, "A map/reduce program that perform word counting.");
// ìœ„ ì½”ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
```


ğŸ“Œ `pgd.addClass("wordcount", Wordcount.class, "A map/reduce program that perform word counting.");`

ìƒˆë¡œìš´ ë§µë¦¬ë“€ìŠ¤ ì½”ë“œë¥¼ ë§Œë“¤ ë•Œë§ˆë‹¤ Driver.java íŒŒì¼ì— pgd.addClassë¡œ ë§Œë“¤ì–´ì„œ append í•´ì•¼ í•¨

Driver.java íŒŒì¼ì´ ë°”ë€Œë©´ Project ë””ë ‰í† ë¦¬ì—ì„œ antë¥¼ ë‹¤ì‹œ ìˆ˜í–‰í•´ì•¼ í•¨

---

ğŸ“Œ **Linuxì—ì„œ ìœ ë‹‰ìŠ¤ ëª‡ê°€ì§€ ëª…ë ¹ì–´ë“¤**

cd, ls, cat (íŒŒì¼ ë‚´ìš© ì¶œë ¥), cp (íŒŒì¼ ë³µì‚¬), mkdir (ìƒˆë¡œìš´ ë””ë ‰í† ë¦¬ ìƒì„±), vi (ì½ê¸°, ìˆ˜ì •)

**HDFSì—ì„œ ìœ ë‹‰ìŠ¤ ëª…ë ¹ì–´ë¥¼ ëŒ€ë¶€ë¶„ ê·¸ëŒ€ë¡œ ì‚¬ìš©**

`hdfs dfs -ìœ ë‹‰ìŠ¤ ëª…ë ¹ì–´` ë¡œ ì‚¬ìš©

---

5. ë§µë¦¬ë“€ìŠ¤ ì½”ë“œ ì»´íŒŒì¼í•˜ê¸°

```bash
$ cd ./hadoop/Project/
$ ant
// Unixì˜ make
// ssafy.jarë¥¼ ìƒì„±
// Project/build.xml ì— ì •ì˜í•œ ëŒ€ë¡œ ìˆ˜í–‰
```

ğŸ“Œ **Hadoopì—ì„œ ë§µë¦¬ë“€ìŠ¤ ìë°” ì½”ë“œ ì‹¤í–‰ ë°©ë²•**

```bash
$ hadoop jar [jar file] [program name] <input arguments ...>
// ex) hadoop jar ssafy.jar wordcount wordcount_test wardcount_test_out
```

`pgd.addClass("wordcount", Wordcount.class, "A map/reduce program that perform word counting.");` ì—ì„œ ì²«ë²ˆì§¸ ì¸ìë¥¼ `[program name]`ì— ë„£ê¸°

---

**Wordcount MapReduce ì•Œê³ ë¦¬ì¦˜ ì½”ë“œ ì‹¤í–‰**

```bash
// home/hadoop ì—ì„œ
$ cd Project/data
~/Project/data$ hdfs dfs -mkdir wordcount_test // wordcount_test ë””ë ‰í† ë¦¬ ìƒì„±
~/Project/data$ hdfs dfs -put wordcount-data.txt wordcount_test // í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ hdfsì— ë³µì‚¬

// ë°˜ë“œì‹œ wordcount_test_out ë””ë ‰í† ë¦¬ë¥¼ ì‚­ì œí•œ í›„ ì‹¤í–‰ í•´ì•¼í•¨
????$ hdfs dfs -rm -r wordcount_test_out

// Hadoop ì‹¤í–‰ (ì•ˆë˜ë©´ ì»´íŒŒì¼ ë‹¤ì‹œ)
~/Project$ hadoop jar ssafy.jar wordcount wordcount_test wordcount_test_out

// ê²°ê³¼ í™•ì¸
// reduce í•¨ìˆ˜ë¥¼ 2ê°œ ì‚¬ìš©í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ì¶œë ¥ íŒŒì¼ì´ 2ê°œ ìƒì„±ë¨
~/Project$ hdfs dfs -cat wordcount_test_out/part-r-00000 | more
~/Project$ hdfs dfs -cat wordcount_test_out/part-r-00001 | more
```

ğŸ“Œ **ìƒˆë¡œìš´ ë§µë¦¬ë“€ìŠ¤ ì•Œê³ ë¦¬ì¦˜ ì½”ë“œë¥¼ ë§Œë“  ë‹¤ìŒì— ì»´íŒŒì¼ì„ í•˜ëŠ” ë°©ë²•**

- ì†ŒìŠ¤ ì½”ë“œ íŒŒì¼ì„ Project/src/ ë””ë ‰í† ë¦¬ì— ë„£ëŠ”ë‹¤.
- Project/src ë””ë ‰í† ë¦¬ì— ìˆëŠ” Driver.java íŒŒì¼ì— append
- Project ë””ë ‰í† ë¦¬ì—ì„œ `ant` ìˆ˜í–‰

---

### ë§µë¦¬ë“€ìŠ¤ ì…ì¶œë ¥ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë””í´íŠ¸ í´ë˜ìŠ¤

ë§µë¦¬ë“€ìŠ¤ ì…ì¶œë ¥ì— ì‚¬ìš©ë˜ëŠ” íƒ€ì…ì€ ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆìŒ

**ì…ì¶œë ¥ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í´ë˜ìŠ¤ì™€ í•´ë‹¹ ìë°” íƒ€ì…**

- Text: string
- IntWritable: int
- LongWritable: long
- FloatWritable: float
- DoubleWritable: double

ë§Œì•½ ìƒˆë¡œìš´ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•´ì„œ ì…ì¶œë ¥ì— ì‚¬ìš©í•˜ê³  ì‹¶ìœ¼ë©´ í•„ìš”í•œ ì—¬ëŸ¬ í•¨ìˆ˜ë„ ê°™ì´ ì •ì˜í•´ì¤˜ì•¼ í•¨